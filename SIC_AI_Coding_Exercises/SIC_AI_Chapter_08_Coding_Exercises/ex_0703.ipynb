{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Exercise #0703"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Softmax regression (multi-class logistic regression):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Read in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use Iris data.\n",
    "# 4 explanatory variables.\n",
    "# 3 classes for the response variable.\n",
    "data_raw = load_iris()\n",
    "data_raw.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the description.\n",
    "# print(data_raw['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_raw['data']\n",
    "y = data_raw['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape.\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Data pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot-Encoding.\n",
    "y = np.array(pd.get_dummies(y, drop_first=False))               # drop_frist = False for one-hot-encoding.\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "X = scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)\n",
    "n_train_size = y_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Do the necessary definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100                                # Size of each (mini) batch.\n",
    "n_epochs  = 30000                               # Number of epochs.\n",
    "learn_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.ones([4,3]))                 # Initial value of the weights = 1.\n",
    "b = tf.Variable(tf.ones([3]))                   # Initial value of the bias = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ph = tf.placeholder(tf.float32, shape=(None, 4))    # Number of rows not specified. Number of columns = numbmer of X variables = 4.\n",
    "y_ph = tf.placeholder(tf.float32, shape=(None,3))     # Number of rows not specified. Number of columns = number of classes of the y variable = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model.\n",
    "# Not strictly necessary to apply the softmax activation. => in the end we will apply argmax() function to predict the label!\n",
    "# y_model = tf.nn.softmax(tf.matmul(X_ph, W) + b)\n",
    "# The following will work just fine.\n",
    "y_model = tf.matmul(X_ph, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss  = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_ph, logits=y_model))     # Loss = cross entropy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learn_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = optimizer.minimize(loss)                                                                    # Define training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()                                                            # Define Variable initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Training and Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "        # Variables initialization.\n",
    "        sess.run(init)\n",
    "        # Training.\n",
    "        for i in range(n_epochs):\n",
    "            idx_rnd = np.random.choice(range(n_train_size),batch_size,replace=False)      # Random sampling w/o replacement for the batch indices.                \n",
    "            batch_X, batch_y = [X_train[idx_rnd,:], y_train[idx_rnd,:]]                   # Get a batch.          \n",
    "            my_feed = {X_ph:batch_X, y_ph:batch_y}                                        # Prepare the feed data as a dictionary.\n",
    "            sess.run(train, feed_dict = my_feed)\n",
    "            if (i + 1) % 2000 == 0: print(\"Step : {}\".format(i + 1))                      # Print the step number at every multiple of 2000.\n",
    "        # Testing.\n",
    "        correct_predictions = tf.equal(tf.argmax(y_ph, axis=1), tf.argmax(y_model, axis=1))   # In argmax(), axis=1 means horizontal direction.\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))                   # Recast the Boolean as float32 first. Then calculate the mean.\n",
    "        accuracy_value = sess.run(accuracy, feed_dict={X_ph:X_test, y_ph:y_test})             # Actually run the test with the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the testing result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy = {:5.3f}\".format(accuracy_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
